{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_SGNS_git.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:Anaconda3]",
      "language": "python",
      "name": "conda-env-Anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Iqpw2_dmYfP1",
        "outputId": "9c44d7e8-e0f1-43b5-88c6-4d4f6bd258d3"
      },
      "source": [
        "#Make a sigle list of collections of strigs of partial sentences\n",
        "#dependencies\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import csv\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "path = '/content/Data.csv'\n",
        "\n",
        "#read the book\n",
        "def read_corpus(path):\n",
        "    f = open(path, encoding=\"utf-8\")\n",
        "    csv_f = csv.reader(f)\n",
        "\n",
        "    book = []\n",
        "    for row in csv_f:\n",
        "        book.append(row[0])\n",
        "    \n",
        "    return book\n",
        "\n",
        "#processing get desired corpus, finding uniq set of words\n",
        "def preprocess(corpus):\n",
        "    \n",
        "    #join the string into a long single string\n",
        "    whole_corpus=' '.join(corpus)\n",
        "\n",
        "    #lower case and remove all the symbols\n",
        "    #then remove the digits\n",
        "    words_no_dig_punc = (re.sub(r'[^\\w]', ' ', whole_corpus.lower())).split()\n",
        "    words_no_dig_punc = [x for x in words_no_dig_punc if not any(c.isdigit() for c in x)]\n",
        "\n",
        "    #finding unique words\n",
        "    #Count and find most common words\n",
        "    from collections import Counter\n",
        "    word_counts = Counter(words_no_dig_punc)\n",
        "    word_counts = word_counts.most_common()   #A sorted version\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    \n",
        "    #Make a corpus without these stop words\n",
        "    vocab = list(filter(lambda x: x not in stop_words, words_no_dig_punc))\n",
        "    \n",
        "    #From corpus get all uniq words --> to be indexed and tokenized (to one hot vectors)\n",
        "    uniq_words = list(set(vocab))\n",
        "    \n",
        "    words_to_ints ={k: v for v, k in enumerate(uniq_words)}  #Redundant, Not using it\n",
        "    ints_to_words ={v: k for v, k in enumerate(uniq_words)}  #Redundant, Not using it\n",
        "\n",
        "    #To tokenize all the words in corpus the indices of words in uniq_words work as look up table\n",
        "    vocab_int_pair= []\n",
        "    for i in range(len(vocab)):\n",
        "        vocab_int_pair.append([vocab[i], uniq_words.index(vocab[i])])\n",
        "\n",
        "    #Finally just take the tokenized version of corpus to be loaded into network to train    \n",
        "    int_arr_of_vocab = np.array(vocab_int_pair)[:, 1].astype(np.int)\n",
        "    \n",
        "    return (whole_corpus, vocab, uniq_words, words_to_ints,  vocab_int_pair, ints_to_words, int_arr_of_vocab)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ej5Uy6nYfP4",
        "outputId": "1eca3d95-e5d8-4a61-ab07-4bb3135e357a"
      },
      "source": [
        "corpus = read_corpus(path)\n",
        "whole_corpus, vocab, uniq_words, words_to_ints,  vocab_int_pair, ints_to_words, int_arr_of_vocab =preprocess(corpus[:400]) \n",
        "for i in range(5):\n",
        "  print(vocab[i],\"->\",int_arr_of_vocab[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prime -> 149\n",
            "minister -> 1394\n",
            "narendra -> 747\n",
            "modi -> 716\n",
            "met -> 1231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mEaC9wpPYfP8"
      },
      "source": [
        "###############################################################################################\n",
        "#Generating pairs of  true samples -->co-occuring within a given frame of window size, labeling the pair 1\n",
        "#int_arr_of_vocab --> Tokenized corpus\n",
        "#window --> Selected window\n",
        "#True pairs start at index +w and ends at index -w (length - w), as only these have full complement of pairs\n",
        "#Much easier to code this way than accomodating all elements for all window sizes\n",
        "\n",
        "def gen_true(int_arr_of_vocab, window):\n",
        "    \n",
        "    true_list = []\n",
        "    \n",
        "    #temp list initially collects 11 indices, however middle one is deleted\n",
        "    #On the second go, middle index is combined with all 10 in temp seperately and labeled as 1\n",
        "    for i in range(len(int_arr_of_vocab)-window*2):\n",
        "        tempp = []\n",
        "        tempp=list(int_arr_of_vocab[i:i+ (window *2) + 1 ]) \n",
        "        tempp.remove(int_arr_of_vocab[i+window])\n",
        "\n",
        "        for j in range(window*2):\n",
        "            true_list.append([int_arr_of_vocab[i+window], tempp[j], 1])\n",
        "    return true_list\n",
        "###################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kfNQxbFvYfP9"
      },
      "source": [
        "###############################################################################################\n",
        "\n",
        "#int_arr_of_vocab --> Tokenized corpus\n",
        "#window --> Selected window\n",
        "#k --> is number of negative samples for each word --> keep 20 as each word as 10 positive pairs when window is size  10\n",
        "#Simply take k random samples from whole set of uniq_words and pair with each input word\n",
        "#Note that each input has window *2 true pairs and k has to be proportionately large\n",
        "\n",
        "#Alternate version, not used here\n",
        "#speed it up --> draw enough random samples in a range\n",
        "#concatenate --> the each item in true copied 20 x, random samples, 0s\n",
        "\n",
        "\n",
        "import random\n",
        "def gen_false(int_arr_of_vocab, uniq_words, k, window):\n",
        "    false_pairs = []\n",
        "    for i in range(len(int_arr_of_vocab)):\n",
        "        rnd_indices = random.sample(range(len(uniq_words)),  k)\n",
        "        for j in range(k):\n",
        "                false_pairs.append([int_arr_of_vocab[i], rnd_indices[j], 0])\n",
        "    \n",
        "    return false_pairs[k*window:-k*window]\n",
        "\n",
        "#Remove the first few pairs and last few pairs as true pairs start at index +w and ends at index -w (length - w)\n",
        "##############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lhbxRfd3YfP-"
      },
      "source": [
        "true_list = gen_true(int_arr_of_vocab, window=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZNcyOfDYfQA",
        "outputId": "883000cf-5efd-4133-8f56-c1633719ca4f"
      },
      "source": [
        "vocab_int_pair[:11], true_list[:11], len(true_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['prime', 149],\n",
              "  ['minister', 1394],\n",
              "  ['narendra', 747],\n",
              "  ['modi', 716],\n",
              "  ['met', 1231],\n",
              "  ['majesty', 1863],\n",
              "  ['queen', 1430],\n",
              "  ['maxima', 1764],\n",
              "  ['kingdom', 588],\n",
              "  ['netherlands', 518],\n",
              "  ['today', 823]],\n",
              " [[747, 149, 1],\n",
              "  [747, 1394, 1],\n",
              "  [747, 716, 1],\n",
              "  [747, 1231, 1],\n",
              "  [716, 1394, 1],\n",
              "  [716, 747, 1],\n",
              "  [716, 1231, 1],\n",
              "  [716, 1863, 1],\n",
              "  [1231, 747, 1],\n",
              "  [1231, 716, 1],\n",
              "  [1231, 1863, 1]],\n",
              " 17264)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7LYJ9t5WYfQB"
      },
      "source": [
        "false_list = gen_false(int_arr_of_vocab, uniq_words, k = 100, window = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "L25YdO6PYfQD"
      },
      "source": [
        "###########################################################################################################\n",
        "#Concatenate true_list, false_list\n",
        "#False list keeps changing each time joint list is drawn\n",
        "def gen_joint_list(true_list,int_arr_of_vocab, uniq_words, k, window ):\n",
        "    joint_list = np.concatenate((np.array(true_list), np.array(gen_false(int_arr_of_vocab, uniq_words, k, window))), axis = 0)\n",
        "    np.random.shuffle(joint_list)\n",
        "    return joint_list\n",
        "############################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86iVlp_oilrh"
      },
      "source": [
        "joint_list=gen_joint_list(true_list,int_arr_of_vocab,uniq_words,100,window=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bllkAQMxYfQF"
      },
      "source": [
        "#########################################################################################\n",
        "#As joint list is too long and takes a lot of memory to process at one go --> load small batches\n",
        "# i --> is used to return one batch at a time, it is a counter and a markers for selecting size\n",
        "#len(joint_list)//batch_size +1 --> gives the total numbers of batches\n",
        "\n",
        "def gen_batch(joint_list, batch_size, i):\n",
        "\n",
        "    if i < len(joint_list)//batch_size:\n",
        "        \n",
        "        batch = joint_list[i*batch_size:i*batch_size+batch_size]\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        batch = joint_list[i*batch_size:]\n",
        "        \n",
        "    return batch\n",
        "############################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJYafyk2YfQG"
      },
      "source": [
        "#Test batch b1\n",
        "b1 = gen_batch(joint_list, batch_size = 100, i =0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CKq31_PcYfQH"
      },
      "source": [
        "###########################################################################################################\n",
        "import torch\n",
        "\n",
        "#generate tensors of one hot vector for each tokenized pair in a batch of joint list\n",
        "#Also note labels are simply 3rd column in each batch\n",
        "\n",
        "def one_hot_auto_batchwise(batch, uniq_words):\n",
        "    \n",
        "    iol_tensor = torch.Tensor(batch).long()\n",
        "    \n",
        "    \n",
        "    middle_word_arr = torch.zeros(iol_tensor.shape[0], len(uniq_words))\n",
        "    sur_word_arr = torch.zeros(iol_tensor.shape[0], len(uniq_words))\n",
        "    for i in range(len(iol_tensor)):\n",
        "        middle_word_arr[i, iol_tensor[i, 0]] = 1\n",
        "        sur_word_arr[i, iol_tensor[i, 1]] = 1\n",
        "    labels = iol_tensor[:, 2].float()\n",
        "    return (middle_word_arr, sur_word_arr, labels)\n",
        "#################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJJ5eaPwYfQI"
      },
      "source": [
        "#with test batch b1 get the respective vectors and labels\n",
        "mh, sh, ll = one_hot_auto_batchwise(b1, uniq_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UZlkXqA2YfQK"
      },
      "source": [
        "#Defining the network\n",
        "#2 linear fully connected layers are used, bias units are not use\n",
        "#fc_midl_word takes all the input words/tokens\n",
        "#fc_sur_word takes all the targets (true or false counterpart) of the pair\n",
        "#Using sigmoid activation hence BCE loss\n",
        "#Also note parameters of both networks are combined in a list which helps in back prop and stepping\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embed_size = 30\n",
        "def gen_model(uniq_words, embed_size, LR=0.0001):\n",
        "    \n",
        "\n",
        "    fc_midl_word = nn.Linear(len(uniq_words), embed_size, bias = False)\n",
        "    fc_sur_word = nn.Linear(len(uniq_words), embed_size, bias = False)\n",
        "\n",
        "    fc_midl_word = fc_midl_word.to(device)\n",
        "    fc_sur_word =fc_sur_word.to(device)\n",
        "\n",
        "    \n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    params = list(fc_midl_word.parameters()) + list(fc_sur_word.parameters())\n",
        "    optimizer = optim.Adam(params, lr = LR)\n",
        "    \n",
        "    return(fc_midl_word, fc_sur_word, criterion, optimizer )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmUcPx-cYfQL"
      },
      "source": [
        "fc_midl_word, fc_sur_word, criterion, optimizer = gen_model(uniq_words, embed_size =30, LR=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7kw3JLwYfQM",
        "outputId": "12f25526-b7ac-4877-9786-c55082af2592"
      },
      "source": [
        "#Collect losses\n",
        "#k --> proporion of negative samples --> with window of 5, k of 100 --> 10 negative samples for each tre pair\n",
        "#window --> selected/defined window for cooccurence\n",
        "#LR - Learing rate\n",
        "#embed_size - Size of embedding for vector representation\n",
        "#embed_size --> Arbitrary, May be scaled down by some log when uniq_set is large or by root when uniq_set is not so large\n",
        "\n",
        "#Get all the variable and network ready before feeding/starting algorithm\n",
        "#xavier init is vital for better and faster convergence\n",
        "\n",
        "losses = []\n",
        "k = 100\n",
        "window = 2\n",
        "LR = 0.001\n",
        "embed_size =30\n",
        "whole_corpus, vocab, uniq_words, words_to_ints,  vocab_int_pair, ints_to_words, int_arr_of_vocab =preprocess(corpus[:400]) \n",
        "true_list = gen_true(int_arr_of_vocab, window =2)\n",
        "\n",
        "\n",
        "fc_midl_word, fc_sur_word, criterion, optimizer = gen_model(uniq_words, embed_size, LR)\n",
        "torch.nn.init.xavier_uniform_(fc_midl_word.weight)\n",
        "torch.nn.init.xavier_uniform_(fc_sur_word.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0263, -0.0342,  0.0287,  ...,  0.0177,  0.0549, -0.0181],\n",
              "        [-0.0223,  0.0334,  0.0498,  ...,  0.0293,  0.0514,  0.0071],\n",
              "        [-0.0428, -0.0257, -0.0249,  ..., -0.0329,  0.0011,  0.0004],\n",
              "        ...,\n",
              "        [-0.0533, -0.0244,  0.0492,  ...,  0.0383,  0.0178, -0.0486],\n",
              "        [-0.0320,  0.0350,  0.0095,  ...,  0.0382, -0.0264, -0.0246],\n",
              "        [ 0.0017,  0.0112, -0.0447,  ..., -0.0155, -0.0122, -0.0344]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOIXSCAXYfQN",
        "outputId": "05732173-9447-46df-e37f-9f2595caacd4"
      },
      "source": [
        "#Implement \n",
        "\n",
        "\n",
        "epochs = 200\n",
        "print_every = 20\n",
        "batch_size = 512\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    #Get fresh joint list with different random false samples\n",
        "    joint_list = gen_joint_list(true_list,int_arr_of_vocab, uniq_words, k, window )\n",
        "    num_batches = (len(joint_list)//batch_size) +1\n",
        "    \n",
        "    #Get i.th batch from joint list and proceed forward, backward\n",
        "    for i in range(num_batches):  \n",
        "        \n",
        "        batch = gen_batch(joint_list, batch_size, i)\n",
        "        mid_word_oh, sur_word_oh, labels = one_hot_auto_batchwise(batch, uniq_words)\n",
        "    \n",
        "    \n",
        "        z_midl = fc_midl_word(torch.Tensor(mid_word_oh))\n",
        "        \n",
        "        z_sur = fc_sur_word(torch.Tensor(sur_word_oh))\n",
        "        \n",
        "        #vector product of word as input and word as target, not the product is parallelized and not looped\n",
        "        #after training product/score for true pairs will be high and low/neg for false pairs\n",
        "        dot_inp_tar = torch.sum(torch.mul(z_midl, z_sur), dim =1).reshape(-1, 1)\n",
        "        \n",
        "        #sigmoid activation squashes the scores to 1 or 0\n",
        "        sig_logits = nn.Sigmoid()(dot_inp_tar)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(sig_logits, torch.Tensor(labels).view(sig_logits.shape[0], 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "    if epoch % print_every == 0:\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        print(loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.16694580018520355\n",
            "0.08674576878547668\n",
            "0.04377136006951332\n",
            "0.03595566004514694\n",
            "0.026900755241513252\n",
            "0.028999585658311844\n",
            "0.02330128662288189\n",
            "0.03742794692516327\n",
            "0.022730093449354172\n",
            "0.017504464834928513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "t59D5yeOYfQQ"
      },
      "source": [
        "#################################################################################################################\n",
        "#Given the set of uniq_words used to train, the function finds the cosine distances from selected word to all words\n",
        "#top_n words are returned, sim_score is simply the cosine distance\n",
        "import torch\n",
        "def find_dist(uniq_words, word, top_n):\n",
        "    distances = []\n",
        "    idx =  uniq_words.index(word)\n",
        "    for i in range(fc_midl_word.weight.t().shape[0]):\n",
        "        dist = nn.CosineSimilarity(dim = 0)(fc_midl_word.weight.t()[idx, :], fc_midl_word.weight.t()[i, :])\n",
        "        distances.append(dist)\n",
        "    sim_score, indices = torch.topk(torch.Tensor(distances), top_n)\n",
        "    indices = indices.tolist()\n",
        "    similar_words = [uniq_words[i] for i  in indices]\n",
        "    #print(similar_words)\n",
        "    print(sim_score)\n",
        "    return similar_words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxuD7R62vdoF",
        "outputId": "861d2c3a-1cc6-421e-e6c0-37369d494f44"
      },
      "source": [
        "uniq_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elaborated',\n",
              " 'approach',\n",
              " 'approximately',\n",
              " 'non',\n",
              " 'methanol',\n",
              " 'generations',\n",
              " 'spread',\n",
              " 'stockholding',\n",
              " 'tried',\n",
              " 'dollars',\n",
              " 'star',\n",
              " 'half',\n",
              " 'ncc',\n",
              " 'cabinet',\n",
              " 'rains',\n",
              " 'enterprises',\n",
              " 'bhanupratappur',\n",
              " 'early',\n",
              " 'improve',\n",
              " 'msme',\n",
              " 'enjoy',\n",
              " 'advice',\n",
              " 'caste',\n",
              " 'breakthroughs',\n",
              " 'act',\n",
              " 'bakula',\n",
              " 'high',\n",
              " 'alliance',\n",
              " 'kutumbakam',\n",
              " 'market',\n",
              " 'solving',\n",
              " 'embrace',\n",
              " 'time',\n",
              " 'led',\n",
              " 'globe',\n",
              " 'operationalization',\n",
              " 'initially',\n",
              " 'noted',\n",
              " 'eleventh',\n",
              " 'wto',\n",
              " 'protects',\n",
              " 'useful',\n",
              " 'jointly',\n",
              " 'last',\n",
              " 'upcoming',\n",
              " 'sessions',\n",
              " 'face',\n",
              " 'foster',\n",
              " 'globalization',\n",
              " 'aviation',\n",
              " 'lalchhahimi',\n",
              " 'helps',\n",
              " 'olympian',\n",
              " 'memorandum',\n",
              " 'financial',\n",
              " 'srinagar',\n",
              " 'conversion',\n",
              " 'rich',\n",
              " 'advanced',\n",
              " 'expert',\n",
              " 'wide',\n",
              " 'statue',\n",
              " 'active',\n",
              " 'well',\n",
              " 'forensic',\n",
              " 'tough',\n",
              " 'appropriate',\n",
              " 'stone',\n",
              " 'several',\n",
              " 'raj',\n",
              " 'difference',\n",
              " 'train',\n",
              " 'bhimrao',\n",
              " 'fighter',\n",
              " 'involvement',\n",
              " 'girls',\n",
              " 'decades',\n",
              " 'primary',\n",
              " 'working',\n",
              " 'competitively',\n",
              " 'objectives',\n",
              " 'often',\n",
              " 'effectively',\n",
              " 'level',\n",
              " 'walk',\n",
              " 'mini',\n",
              " 'skill',\n",
              " 'vote',\n",
              " 'automatic',\n",
              " 'provision',\n",
              " 'officer',\n",
              " 'making',\n",
              " 'wearing',\n",
              " 'tribute',\n",
              " 'jwg',\n",
              " 'five',\n",
              " 'bio',\n",
              " 'spirit',\n",
              " 'parts',\n",
              " 'saving',\n",
              " 'find',\n",
              " 'positive',\n",
              " 'fulfilling',\n",
              " 'generating',\n",
              " 'rights',\n",
              " 'humanitarian',\n",
              " 'seeks',\n",
              " 'problems',\n",
              " 'radicalization',\n",
              " 'law',\n",
              " 'tune',\n",
              " 'plants',\n",
              " 'spared',\n",
              " 'filled',\n",
              " 'came',\n",
              " 'go',\n",
              " 'tourism',\n",
              " 'interferometer',\n",
              " 'h',\n",
              " 'realities',\n",
              " 'ष',\n",
              " 'autonomous',\n",
              " 'bid',\n",
              " 'taken',\n",
              " 'arena',\n",
              " 'jayanti',\n",
              " 'dedication',\n",
              " 'confident',\n",
              " 'easier',\n",
              " 'geo',\n",
              " 'paved',\n",
              " 'pensioner',\n",
              " 'produce',\n",
              " 'lasting',\n",
              " 'catered',\n",
              " 'pilots',\n",
              " 'delivery',\n",
              " 'paying',\n",
              " 'sharp',\n",
              " 'travelled',\n",
              " 'proper',\n",
              " 'benefited',\n",
              " 'programme',\n",
              " 'till',\n",
              " 'protected',\n",
              " 'lowering',\n",
              " 'designs',\n",
              " 'ministerial',\n",
              " 'patient',\n",
              " 'prime',\n",
              " 'news',\n",
              " 'seek',\n",
              " 'growth',\n",
              " 'units',\n",
              " 'chief',\n",
              " 'movement',\n",
              " 'essential',\n",
              " 'fully',\n",
              " 'map',\n",
              " 'abhiyan',\n",
              " 'visionary',\n",
              " 'performed',\n",
              " 'scientist',\n",
              " 'watts',\n",
              " 'layer',\n",
              " 'openness',\n",
              " 'member',\n",
              " 'micro',\n",
              " 'help',\n",
              " 'hesitate',\n",
              " 'exhorted',\n",
              " 'outcome',\n",
              " 'friends',\n",
              " 'pressure',\n",
              " 'ram',\n",
              " 'targeting',\n",
              " 'rohtak',\n",
              " 'das',\n",
              " 'council',\n",
              " 'increased',\n",
              " 'fruition',\n",
              " 'single',\n",
              " 'reformers',\n",
              " 'union',\n",
              " 'streams',\n",
              " 'patan',\n",
              " 'therefore',\n",
              " 'hackathon',\n",
              " 'reduce',\n",
              " 'focus',\n",
              " 'believes',\n",
              " 'must',\n",
              " 'ideas',\n",
              " 'convocation',\n",
              " 'sure',\n",
              " 'kv',\n",
              " 'disasters',\n",
              " 'centre',\n",
              " 'casteism',\n",
              " 'tuberculosis',\n",
              " 'country',\n",
              " 'realized',\n",
              " 'hope',\n",
              " 'button',\n",
              " 'mother',\n",
              " 'cementing',\n",
              " 'encephalitis',\n",
              " 'economic',\n",
              " 'leader',\n",
              " 'offers',\n",
              " 'treatment',\n",
              " 'equal',\n",
              " 'existence',\n",
              " 'boxer',\n",
              " 'conclude',\n",
              " 'empower',\n",
              " 'officials',\n",
              " 'first',\n",
              " 'sourcing',\n",
              " 'k',\n",
              " 'leverage',\n",
              " 'sharing',\n",
              " 'transmission',\n",
              " 'player',\n",
              " 'contacts',\n",
              " 'synonymous',\n",
              " 'raman',\n",
              " 'gives',\n",
              " 'public',\n",
              " 'andhra',\n",
              " 'barriers',\n",
              " 'archer',\n",
              " 'prey',\n",
              " 'districts',\n",
              " 'open',\n",
              " 'literally',\n",
              " 'enactment',\n",
              " 'text',\n",
              " 'benefit',\n",
              " 'suffer',\n",
              " 'section',\n",
              " 'benefiting',\n",
              " 'integrated',\n",
              " 'annual',\n",
              " 'agartala',\n",
              " 'sir',\n",
              " 'chhotu',\n",
              " 'purpose',\n",
              " 'region',\n",
              " 'space',\n",
              " 'ahead',\n",
              " 'ruler',\n",
              " 'prevented',\n",
              " 'ex',\n",
              " 'played',\n",
              " 'rimpochee',\n",
              " 'completion',\n",
              " 'mentored',\n",
              " 'healthy',\n",
              " 'security',\n",
              " 'teams',\n",
              " 'opportunity',\n",
              " 'relations',\n",
              " 'inauguration',\n",
              " 'fortitude',\n",
              " 'leave',\n",
              " 'logo',\n",
              " 'excite',\n",
              " 'models',\n",
              " 'information',\n",
              " 'saha',\n",
              " 'yoga',\n",
              " 'validity',\n",
              " 'rail',\n",
              " 'waterways',\n",
              " 'evils',\n",
              " 'fiscal',\n",
              " 'stands',\n",
              " 'secure',\n",
              " 'abroad',\n",
              " 'carry',\n",
              " 'leaders',\n",
              " 'advocate',\n",
              " 'distance',\n",
              " 'jam',\n",
              " 'technology',\n",
              " 'enhancing',\n",
              " 'paving',\n",
              " 'participative',\n",
              " 'schemes',\n",
              " 'sustainable',\n",
              " 'raises',\n",
              " 'silos',\n",
              " 'establish',\n",
              " 'recent',\n",
              " 'application',\n",
              " 'discovery',\n",
              " 'agro',\n",
              " 'mutual',\n",
              " 'parliamentarian',\n",
              " 'padhao',\n",
              " 'school',\n",
              " 'children',\n",
              " 'networking',\n",
              " 'function',\n",
              " 'inaugurated',\n",
              " 'hours',\n",
              " 'pace',\n",
              " 'commencement',\n",
              " 'years',\n",
              " 'contributes',\n",
              " 'appears',\n",
              " 'evaluated',\n",
              " 'giga',\n",
              " 'alipur',\n",
              " 'excel',\n",
              " 'believe',\n",
              " 'available',\n",
              " 'scientifically',\n",
              " 'called',\n",
              " 'emerging',\n",
              " 'deliberations',\n",
              " 'minds',\n",
              " 'ambitious',\n",
              " 'nepal',\n",
              " 'former',\n",
              " 'rehabilitation',\n",
              " 'quality',\n",
              " 'secretary',\n",
              " 'role',\n",
              " 'pending',\n",
              " 'beneficiary',\n",
              " 'bharatmala',\n",
              " 'surely',\n",
              " 'markets',\n",
              " 'towards',\n",
              " 'reaffirm',\n",
              " 'stakeholders',\n",
              " 'pipeline',\n",
              " 'would',\n",
              " 'specific',\n",
              " 'efforts',\n",
              " 'used',\n",
              " 'surveillance',\n",
              " 'णक',\n",
              " 'focusing',\n",
              " 'motihari',\n",
              " 'efficiency',\n",
              " 'installed',\n",
              " 'differences',\n",
              " 'drinking',\n",
              " 'nepali',\n",
              " 'matters',\n",
              " 'gauge',\n",
              " 'steps',\n",
              " 'cyberspace',\n",
              " 'arrival',\n",
              " 'newer',\n",
              " 'g',\n",
              " 'ease',\n",
              " 'abled',\n",
              " 'engage',\n",
              " 'approved',\n",
              " 'borders',\n",
              " 'albert',\n",
              " 'two',\n",
              " 'investment',\n",
              " 'pension',\n",
              " 'malaria',\n",
              " 'complete',\n",
              " 'footfalls',\n",
              " 'expenditures',\n",
              " 'daughters',\n",
              " 'governance',\n",
              " 'heart',\n",
              " 'provincial',\n",
              " 'longer',\n",
              " 'mahaparinirvana',\n",
              " 'creation',\n",
              " 'said',\n",
              " 'loss',\n",
              " 'landmark',\n",
              " 'sectors',\n",
              " 'motivate',\n",
              " 'visits',\n",
              " 'scheme',\n",
              " 'create',\n",
              " 'sanctioned',\n",
              " 'general',\n",
              " 'worth',\n",
              " 'proposal',\n",
              " 'ji',\n",
              " 'jangla',\n",
              " 'discharge',\n",
              " 'reflects',\n",
              " 'especially',\n",
              " 'diverse',\n",
              " 'solutions',\n",
              " 'interacted',\n",
              " 'chhattisgarh',\n",
              " 'fugitive',\n",
              " 'f',\n",
              " 'traffic',\n",
              " 'reformed',\n",
              " 'workforce',\n",
              " 'second',\n",
              " 'youth',\n",
              " 'unwavering',\n",
              " 'inculcate',\n",
              " 'problem',\n",
              " 'ready',\n",
              " 'welcomed',\n",
              " 'aware',\n",
              " 'missing',\n",
              " 'tripura',\n",
              " 'fighting',\n",
              " 'private',\n",
              " 'mp',\n",
              " 'र',\n",
              " 'deepens',\n",
              " 'attend',\n",
              " 'launched',\n",
              " 'examples',\n",
              " 'formed',\n",
              " 'federalism',\n",
              " 'assumed',\n",
              " 'connectivity',\n",
              " 'statement',\n",
              " 'yangon',\n",
              " 'facilitate',\n",
              " 'confidence',\n",
              " 'grids',\n",
              " 'adopted',\n",
              " 'going',\n",
              " 'recommendations',\n",
              " 'tallest',\n",
              " 'partake',\n",
              " 'sportspersons',\n",
              " 'summit',\n",
              " 'cooperative',\n",
              " 'efficient',\n",
              " 'launch',\n",
              " 'seven',\n",
              " 'reflection',\n",
              " 'civil',\n",
              " 'diplomatic',\n",
              " 'deliver',\n",
              " 'behind',\n",
              " 'end',\n",
              " 'freed',\n",
              " 'provides',\n",
              " 'व',\n",
              " 'ever',\n",
              " 'april',\n",
              " 'bamboo',\n",
              " 'grief',\n",
              " 'college',\n",
              " 'thus',\n",
              " 'strived',\n",
              " 'dahod',\n",
              " 'subjected',\n",
              " 'sitting',\n",
              " 'speaking',\n",
              " 'growing',\n",
              " 'wind',\n",
              " 'merely',\n",
              " 'hour',\n",
              " 'ministers',\n",
              " 'rightful',\n",
              " 'specified',\n",
              " 'traditions',\n",
              " 'releases',\n",
              " 'respective',\n",
              " 'subjects',\n",
              " 'tree',\n",
              " 'solution',\n",
              " 'year',\n",
              " 'justice',\n",
              " 'bodes',\n",
              " 'watt',\n",
              " 'focused',\n",
              " 'healthcare',\n",
              " 'governor',\n",
              " 'dream',\n",
              " 'particularly',\n",
              " 'past',\n",
              " 'sense',\n",
              " 'threats',\n",
              " 'department',\n",
              " 'visiting',\n",
              " 'clarion',\n",
              " 'marketing',\n",
              " 'ground',\n",
              " 'थ',\n",
              " 'sections',\n",
              " 'taking',\n",
              " 'umang',\n",
              " 'origin',\n",
              " 'objective',\n",
              " 'sochi',\n",
              " 'vikas',\n",
              " 'learn',\n",
              " 'full',\n",
              " 'recommend',\n",
              " 'associated',\n",
              " 'identify',\n",
              " 'sukhi',\n",
              " 'wednesday',\n",
              " 'ago',\n",
              " 'develop',\n",
              " 'testing',\n",
              " 'framework',\n",
              " 'menaces',\n",
              " 'transport',\n",
              " 'jyoti',\n",
              " 'diseases',\n",
              " 'statehood',\n",
              " 'electricity',\n",
              " 'netherlands',\n",
              " 'conference',\n",
              " 'athlete',\n",
              " 'expands',\n",
              " 'rename',\n",
              " 'prosperous',\n",
              " 'j',\n",
              " 'aadhaar',\n",
              " 'increase',\n",
              " 'enables',\n",
              " 'million',\n",
              " 'bijapur',\n",
              " 'serves',\n",
              " 'traditional',\n",
              " 'urge',\n",
              " 'got',\n",
              " 'heads',\n",
              " 'appreciated',\n",
              " 'food',\n",
              " 'remains',\n",
              " 'committee',\n",
              " 'rally',\n",
              " 'foundation',\n",
              " 'sports',\n",
              " 'inclusion',\n",
              " 'large',\n",
              " 'twin',\n",
              " 'funding',\n",
              " 'particular',\n",
              " 'added',\n",
              " 'third',\n",
              " 'set',\n",
              " 'trinity',\n",
              " 'defence',\n",
              " 'experiences',\n",
              " 'army',\n",
              " 'commissioned',\n",
              " 'crowd',\n",
              " 'success',\n",
              " 'states',\n",
              " 'village',\n",
              " 'month',\n",
              " 'committed',\n",
              " 'multifaceted',\n",
              " 'digitally',\n",
              " 'proof',\n",
              " 'stuck',\n",
              " 'alusteng',\n",
              " 'awareness',\n",
              " 'received',\n",
              " 'species',\n",
              " 'lakh',\n",
              " 'provide',\n",
              " 'one',\n",
              " 'techniques',\n",
              " 'times',\n",
              " 'excellence',\n",
              " 'singh',\n",
              " 'hydro',\n",
              " 'facility',\n",
              " 'physical',\n",
              " 'adversity',\n",
              " 'prices',\n",
              " 'balance',\n",
              " 'ushering',\n",
              " 'bj',\n",
              " 'tester',\n",
              " 'six',\n",
              " 'break',\n",
              " 'villages',\n",
              " 'kingdom',\n",
              " 'equity',\n",
              " 'reliable',\n",
              " 'perception',\n",
              " 'systems',\n",
              " 'free',\n",
              " 'pronged',\n",
              " 'economies',\n",
              " 'pensioners',\n",
              " 'resulted',\n",
              " 'roads',\n",
              " 'crisis',\n",
              " 'expanded',\n",
              " 'nine',\n",
              " 'functioning',\n",
              " 'reach',\n",
              " 'gender',\n",
              " 'yashpal',\n",
              " 'pradesh',\n",
              " 'century',\n",
              " 'shri',\n",
              " 'agriculture',\n",
              " 'assist',\n",
              " 'expenditure',\n",
              " 'many',\n",
              " 'stressed',\n",
              " 'provided',\n",
              " 'becoming',\n",
              " 'trade',\n",
              " 'north',\n",
              " 'ble',\n",
              " 'strength',\n",
              " 'ahmedabad',\n",
              " 'mankind',\n",
              " 'personnel',\n",
              " 'rajasthan',\n",
              " 'authority',\n",
              " 'finance',\n",
              " 'refurbishing',\n",
              " 'biometric',\n",
              " 'ties',\n",
              " 'highway',\n",
              " 'innovative',\n",
              " 'evil',\n",
              " 'lives',\n",
              " 'expertise',\n",
              " 'dubious',\n",
              " 'amenities',\n",
              " 'land',\n",
              " 'priorities',\n",
              " 'employment',\n",
              " 'accepted',\n",
              " 'greetings',\n",
              " 'medium',\n",
              " 'establishment',\n",
              " 'forces',\n",
              " 'promoting',\n",
              " 'permit',\n",
              " 'importance',\n",
              " 'impression',\n",
              " 'ग',\n",
              " 'october',\n",
              " 'experience',\n",
              " 'surface',\n",
              " 'puts',\n",
              " 'manned',\n",
              " 'chandra',\n",
              " 'families',\n",
              " 'coal',\n",
              " 'represent',\n",
              " 'redefine',\n",
              " 'lifter',\n",
              " 'farm',\n",
              " 'education',\n",
              " 'exclusive',\n",
              " 'silent',\n",
              " 'counter',\n",
              " 'dialysis',\n",
              " 'enterprise',\n",
              " 'myanmar',\n",
              " 'current',\n",
              " 'tech',\n",
              " 'stop',\n",
              " 'regular',\n",
              " 'fruitful',\n",
              " 'wishing',\n",
              " 'completed',\n",
              " 'immense',\n",
              " 'area',\n",
              " 'relatively',\n",
              " 'connecting',\n",
              " 'call',\n",
              " 'facing',\n",
              " 'elements',\n",
              " 'dark',\n",
              " 'future',\n",
              " 'meghnad',\n",
              " 'transition',\n",
              " 'chaudhary',\n",
              " 'avail',\n",
              " 'finalized',\n",
              " 'force',\n",
              " 'pleasure',\n",
              " 'incomes',\n",
              " 'transportation',\n",
              " 'overcome',\n",
              " 'raising',\n",
              " 'socio',\n",
              " 'shied',\n",
              " 'keen',\n",
              " 'laser',\n",
              " 'devoting',\n",
              " 'padma',\n",
              " 'around',\n",
              " 'treated',\n",
              " 'major',\n",
              " 'flying',\n",
              " 'interaction',\n",
              " 'timely',\n",
              " 'railways',\n",
              " 'funds',\n",
              " 'mode',\n",
              " 'capabilities',\n",
              " 'firm',\n",
              " 'smart',\n",
              " 'seconds',\n",
              " 'aspirational',\n",
              " 'underlines',\n",
              " 'modi',\n",
              " 'status',\n",
              " 'friendly',\n",
              " 'minimal',\n",
              " 'famous',\n",
              " 'others',\n",
              " 'romania',\n",
              " 'investigation',\n",
              " 'nearly',\n",
              " 'policies',\n",
              " 'qualitative',\n",
              " 'window',\n",
              " 'alive',\n",
              " 'cadets',\n",
              " 'enabler',\n",
              " 'inaugurate',\n",
              " 'brave',\n",
              " 'aspiration',\n",
              " 'य',\n",
              " 'addressing',\n",
              " 'unveiled',\n",
              " 'cleaner',\n",
              " 'facilitation',\n",
              " 'weight',\n",
              " 'important',\n",
              " 'gst',\n",
              " 'medical',\n",
              " 'engineering',\n",
              " 'visit',\n",
              " 'discussed',\n",
              " 'economically',\n",
              " 'narendra',\n",
              " 'signing',\n",
              " 'floods',\n",
              " 'highlighted',\n",
              " 'direct',\n",
              " 'number',\n",
              " 'us',\n",
              " 'opinion',\n",
              " 'resumore',\n",
              " 'ensure',\n",
              " 'increasing',\n",
              " 'medicinal',\n",
              " 'metro',\n",
              " 'bose',\n",
              " 'income',\n",
              " 'valuable',\n",
              " 'reforming',\n",
              " 'term',\n",
              " 'menace',\n",
              " 'successful',\n",
              " 'augmentation',\n",
              " 'kargil',\n",
              " 'spoke',\n",
              " 'campus',\n",
              " 'signed',\n",
              " 'mandir',\n",
              " 'passenger',\n",
              " 'construction',\n",
              " 'given',\n",
              " 'electrical',\n",
              " 'meet',\n",
              " 'implementation',\n",
              " 'young',\n",
              " 'promotion',\n",
              " 'negotiated',\n",
              " 'changes',\n",
              " 'rs',\n",
              " 'aims',\n",
              " 'priority',\n",
              " 'cleared',\n",
              " 'four',\n",
              " 'principle',\n",
              " 'leakages',\n",
              " 'karkhana',\n",
              " 'cent',\n",
              " 'officers',\n",
              " 'stage',\n",
              " 'course',\n",
              " 'target',\n",
              " 'registration',\n",
              " 'tape',\n",
              " 'geared',\n",
              " 'tunisia',\n",
              " 'vein',\n",
              " 'mark',\n",
              " 'means',\n",
              " 'playground',\n",
              " 'jeevan',\n",
              " 'decisions',\n",
              " 'proportion',\n",
              " 'enacted',\n",
              " 'diagnostic',\n",
              " 'heights',\n",
              " 'institute',\n",
              " 'society',\n",
              " 'need',\n",
              " 'hard',\n",
              " 'purposes',\n",
              " 'alert',\n",
              " 'products',\n",
              " 'commitment',\n",
              " 'money',\n",
              " 'yojana',\n",
              " 'faceted',\n",
              " 'cyber',\n",
              " 'strengthens',\n",
              " 'today',\n",
              " 'trainees',\n",
              " 'far',\n",
              " 'come',\n",
              " 'remain',\n",
              " 'conduct',\n",
              " 'finalised',\n",
              " 'religion',\n",
              " 'office',\n",
              " 'wave',\n",
              " 'activities',\n",
              " 'bombay',\n",
              " 'welfare',\n",
              " 'underscored',\n",
              " 'tuirial',\n",
              " 'potential',\n",
              " 'voice',\n",
              " 'power',\n",
              " 'results',\n",
              " 'equipped',\n",
              " 'properties',\n",
              " 'prof',\n",
              " 'use',\n",
              " 'कलस',\n",
              " 'expressed',\n",
              " 'east',\n",
              " 'co',\n",
              " 'bilateral',\n",
              " 'kranti',\n",
              " 'secretaries',\n",
              " 'ananthapur',\n",
              " 'impeccable',\n",
              " 'day',\n",
              " 'chosen',\n",
              " 'resources',\n",
              " 'dedicated',\n",
              " 'click',\n",
              " 'highlight',\n",
              " 'transforming',\n",
              " 'eliminate',\n",
              " 'capital',\n",
              " 'supplemented',\n",
              " 'achieved',\n",
              " 'mobile',\n",
              " 'centers',\n",
              " 'machinery',\n",
              " 'aizawl',\n",
              " 'dalli',\n",
              " 'sabka',\n",
              " 'lalremsanga',\n",
              " 'journey',\n",
              " 'among',\n",
              " 'make',\n",
              " 'encouraged',\n",
              " 'putin',\n",
              " 'great',\n",
              " 'close',\n",
              " 'district',\n",
              " 'entered',\n",
              " 'deenbandhu',\n",
              " 'special',\n",
              " 'huge',\n",
              " 'forefront',\n",
              " 'heptullah',\n",
              " 'worldwide',\n",
              " 'mentioned',\n",
              " 'add',\n",
              " 'way',\n",
              " 'genetic',\n",
              " 'left',\n",
              " 'globalisation',\n",
              " 'three',\n",
              " 'scientists',\n",
              " 'argentina',\n",
              " 'told',\n",
              " 'climate',\n",
              " 'landing',\n",
              " 'strengthen',\n",
              " 'however',\n",
              " 'smooth',\n",
              " 'careers',\n",
              " 'drive',\n",
              " 'iterate',\n",
              " 'institutions',\n",
              " 'procurement',\n",
              " 'assurance',\n",
              " 'witnessed',\n",
              " 'participated',\n",
              " 'colorful',\n",
              " 'towns',\n",
              " 'source',\n",
              " 'network',\n",
              " 'embarking',\n",
              " 'satisfaction',\n",
              " 'successfully',\n",
              " 'deputy',\n",
              " 'discourse',\n",
              " 'criminals',\n",
              " 'decision',\n",
              " 'labs',\n",
              " 'hydrology',\n",
              " 'days',\n",
              " 'economy',\n",
              " 'fisheries',\n",
              " 'shared',\n",
              " 'triad',\n",
              " 'small',\n",
              " 'discuss',\n",
              " 'media',\n",
              " 'core',\n",
              " 'areas',\n",
              " 'safe',\n",
              " 'dr',\n",
              " 'opportunities',\n",
              " 'entire',\n",
              " 'peace',\n",
              " 'banking',\n",
              " 'inspiration',\n",
              " 'ultimately',\n",
              " 'tradition',\n",
              " 'occasion',\n",
              " 'ur',\n",
              " 'manipur',\n",
              " 'bsf_india',\n",
              " 'various',\n",
              " 'mandatory',\n",
              " 'could',\n",
              " 'handled',\n",
              " 'offenders',\n",
              " 'expanding',\n",
              " 'sponsored',\n",
              " 'invitation',\n",
              " 'haryana',\n",
              " 'affected',\n",
              " 'financing',\n",
              " 'marketplace',\n",
              " 'irrespective',\n",
              " 'dignitaries',\n",
              " 'bhagidari',\n",
              " 'convinced',\n",
              " 'lineand',\n",
              " 'aires',\n",
              " 'tweeples',\n",
              " 'state',\n",
              " 'become',\n",
              " 'experts',\n",
              " 'netaji',\n",
              " 'oli',\n",
              " 'respect',\n",
              " 'despite',\n",
              " 'liberate',\n",
              " 'laid',\n",
              " 'attending',\n",
              " 'soil',\n",
              " 'south',\n",
              " 'drass',\n",
              " 'sons',\n",
              " 'unprecedented',\n",
              " 'mumbai',\n",
              " 'elections',\n",
              " 'strongly',\n",
              " 'due',\n",
              " 'service',\n",
              " 'processes',\n",
              " 'fruits',\n",
              " 'billions',\n",
              " 'vulnerable',\n",
              " 'address',\n",
              " 'eco',\n",
              " 'legal',\n",
              " 'historical',\n",
              " 'gudum',\n",
              " 'transformative',\n",
              " 'privacy',\n",
              " 'lack',\n",
              " 'feel',\n",
              " 'hima',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyA_uK3rYfQU",
        "outputId": "da59c37e-72b1-416c-8310-5c4c83599eba"
      },
      "source": [
        "find_dist(uniq_words, 'prime', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 0.7824, 0.6576, 0.5876, 0.5871, 0.5843, 0.5785, 0.5697, 0.5670,\n",
            "        0.5661])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prime',\n",
              " 'minister',\n",
              " 'saluted',\n",
              " 'maharashtra',\n",
              " 'rich',\n",
              " 'indulging',\n",
              " 'spiritual',\n",
              " 'bj',\n",
              " 'occasion',\n",
              " 'medical']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV9Oz3KVYfQV",
        "outputId": "a5178aea-c43c-46b7-ccf5-9c0e2d83df58"
      },
      "source": [
        "find_dist(uniq_words, 'president', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 0.8288, 0.8194, 0.7697, 0.7630, 0.6891, 0.6882, 0.6512, 0.6435,\n",
            "        0.6354])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['president',\n",
              " 'tomorrow',\n",
              " 'sochi',\n",
              " 'former',\n",
              " 'russian',\n",
              " 'prior',\n",
              " 'putin',\n",
              " 'huge',\n",
              " 'electricity',\n",
              " 'asserted']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy0qsTBovNJT",
        "outputId": "f6d40764-8db1-4288-8569-ca96ac4db184"
      },
      "source": [
        "find_dist(uniq_words, 'develop', 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 0.6639, 0.6576, 0.6506, 0.6452, 0.6436, 0.6428, 0.6399, 0.6345,\n",
            "        0.6277])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['develop',\n",
              " 'shining',\n",
              " 'mechanism',\n",
              " 'clean',\n",
              " 'unnecessary',\n",
              " 'tunisia',\n",
              " 'executing',\n",
              " 'successful',\n",
              " 'upon',\n",
              " 'newer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}